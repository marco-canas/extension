{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc06dec7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/extension/blob/main/taller_g_lideres/6_churn/1_analisis_abandono.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/marco-canas/extension/blob/main/taller_g_lideres/6_churn/1_analisis_abandono.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5b198",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Video de apoyo a la lectura interactiva y experimental de este cuaderno](https://www.youtube.com/watch?v=D5RHi4KWW8k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e82203",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Vínculo al programa del curso de Introducción al machine learning:](https://github.com/marco-canas/didactica_ciencia_datos/tree/main/1_curso_machine_learning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ab06d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un reconocimiento a mis estudiantes que han construido conmigo este saber pedagógico:\n",
    "\n",
    "<img src = 'https://github.com/marco-canas/extension/blob/main/taller_g_lideres/images_of_students/g_lideres_ml_for_bootcamps_2024_10_10.jpeg?raw=true' width = 600> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74a56c-0ce6-4ad6-b985-553fd7fb68bb",
   "metadata": {},
   "source": [
    "Reconocimiento a las profesoras destacadas en enseñanza: Lorena Barba\n",
    "\n",
    "[flipped class](https://lorenabarba.com/news/flipped-class-energizes-cfd/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97dc80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fomento de la lectura literaria asociada a Ingeniería agropecuaria y licenciatura en Matemáticas\n",
    "\n",
    "[Aprender a negociar de Roger Fisher](https://github.com/marco-canas/el_arte_de_aprender_a_negociar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96775931",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Título de la clase: Análisis de riesgo de deserción de clientes con técnicas de Machine Learning \n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d38dd4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objetivo de aprendizaje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6941ec",
   "metadata": {},
   "source": [
    "\n",
    "Esta es una lista de objetivos de enseñanza para un taller sobre *Análisis de riesgo de deserción de clientes en una empresa de telecomunicaciones con técnicas de machine learning*, orientado a unas jornadas de investigación. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2fe12",
   "metadata": {},
   "source": [
    "Estos objetivos están diseñados para guiar tanto la comprensión de los conceptos como la aplicación práctica de modelos de machine learning:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3402bc2",
   "metadata": {},
   "source": [
    "\n",
    "### Objetivos de Enseñanza\n",
    "\n",
    "1. **Comprender el contexto del análisis de riesgo de deserción**:  \n",
    "   Introducir el concepto de *churn* o deserción de clientes en telecomunicaciones, su impacto financiero y la importancia de predecirlo para la toma de decisiones estratégicas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a1cf0",
   "metadata": {},
   "source": [
    "\n",
    "2. **Analizar y preparar los datos de clientes para modelos de machine learning**:  \n",
    "   Identificar y limpiar datos relevantes de clientes (transacciones, demografía, comportamiento, entre otros) y aplicar técnicas de preprocesamiento (gestión de valores faltantes, codificación de variables, escalamiento de los datos).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138a7eb",
   "metadata": {},
   "source": [
    "\n",
    "3. **Explorar técnicas de machine learning para la predicción de deserción**:  \n",
    "   Describir y discutir los principales modelos supervisados aplicables, como la regresión logística, árboles de decisión, bosques aleatorios (Random Forest), y algoritmos de clasificación como SVM (Support Vector Machines) y redes neuronales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf067d",
   "metadata": {},
   "source": [
    "\n",
    "4. **Implementar modelos de machine learning para predecir el riesgo de deserción**:  \n",
    "   Guiar la construcción paso a paso de un modelo predictivo para churn, utilizando Python y bibliotecas como Scikit-Learn o TensorFlow, desde el diseño hasta la implementación del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd5174",
   "metadata": {},
   "source": [
    "\n",
    "5. **Evaluar el desempeño del modelo predictivo**:  \n",
    "   Explicar y aplicar métricas de evaluación (precisión, recall, F1-score, AUC-ROC) para determinar la efectividad del modelo en la predicción de deserción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f85c0",
   "metadata": {},
   "source": [
    "\n",
    "6. **Interpretar los resultados y los factores clave de deserción**:  \n",
    "   Utilizar técnicas como el análisis de características importantes (feature importance) y técnicas de interpretabilidad (como SHAP y LIME) para identificar los factores de riesgo más relevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf0f20",
   "metadata": {},
   "source": [
    "\n",
    "7. **Realizar ajustes y optimización del modelo**:  \n",
    "   Implementar técnicas de ajuste de hiperparámetros (grid search, random search) para mejorar la precisión y robustez del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f93432",
   "metadata": {},
   "source": [
    "\n",
    "8. **Presentar un caso práctico de uso en telecomunicaciones**:  \n",
    "   Analizar un caso de estudio en el cual se implementa el modelo de churn en una empresa de telecomunicaciones, destacando los beneficios y retos de llevar el modelo a producción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7d638",
   "metadata": {},
   "source": [
    "\n",
    "9. **Identificar estrategias de retención de clientes basadas en resultados predictivos**:  \n",
    "   Desarrollar recomendaciones estratégicas basadas en los hallazgos para implementar acciones específicas de retención de clientes en telecomunicaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad92807e",
   "metadata": {},
   "source": [
    "\n",
    "10. **Evaluar aspectos éticos y de privacidad en el uso de datos para predicción de deserción**:  \n",
    "    Reflexionar sobre la importancia de la privacidad y el uso ético de los datos de clientes en el análisis de riesgo y la implementación de modelos de machine learning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de76f071",
   "metadata": {},
   "source": [
    "\n",
    "Estos objetivos proporcionan una guía estructurada para el desarrollo del taller, asegurando que los participantes adquieran habilidades prácticas y comprensión teórica sobre el análisis de deserción de clientes en telecomunicaciones mediante machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0addfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapa conceptual para cada clase  \n",
    "from graphviz import Digraph\n",
    "\n",
    "# Crear un nuevo grafo dirigido\n",
    "dot = Digraph()\n",
    "\n",
    "# Añadir nodos y relaciones al grafo\n",
    "main_concept = 'Predicción de abandono'\n",
    "dot.node('A', main_concept)\n",
    "dot.node('B', 'Contextualización')\n",
    "dot.node('C', 'Obtención de datos')\n",
    "dot.node('D', 'Síntesis Tabulares')\n",
    "dot.node('E', 'Visualizacion \\n atributos categóricos')\n",
    "dot.node('F', 'Visualización de \\n variables cuantitativas continuas')\n",
    "dot.node('G', 'Análisis de correlaciones')\n",
    "dot.node('H', 'Correlaciones entre targent categorico\\n y predictores continuos')\n",
    "\n",
    "dot.edges(['AB', 'BC', 'CD', 'DE', 'EF', 'FG', 'GH']) \n",
    "\n",
    "# Guardar el grafo como un archivo de imagen\n",
    "dot.render(filename=main_concept, format='png', cleanup=True)\n",
    "\n",
    "dot.view()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e55ccf",
   "metadata": {},
   "source": [
    "# Análisis de riesgo de deserción de clientes  \n",
    "\n",
    "[El dataset es de kaggle](https://www.kaggle.com/datasets/geoamins/telco-customer-churn-ibm?resource=download)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccedc56",
   "metadata": {},
   "source": [
    "<img src = 'https://i.ytimg.com/vi/BV03sQ0srcU/hqdefault.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12a187",
   "metadata": {},
   "source": [
    "Este dataset es conocido como **Telco Customer Churn IBM** y contiene información de clientes de una compañía de telecomunicaciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cb4d20",
   "metadata": {},
   "source": [
    "Se utiliza principalmente para analizar y predecir la deserción de clientes, es decir, el riesgo de que un cliente cancele su servicio o deje de usar los productos de la compañía. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a52c5",
   "metadata": {},
   "source": [
    "Este tipo de análisis es importante para las empresas, ya que les permite identificar patrones y comportamientos que pueden llevar a la pérdida de clientes, con el fin de tomar acciones preventivas para retenerlos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575ed7b",
   "metadata": {},
   "source": [
    "\n",
    "## Descripción de las variables:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a2208",
   "metadata": {},
   "source": [
    "\n",
    "1. **Estado (state)**: Esta variable indica el estado de origen del cliente. Puede ayudar a detectar si hay patrones geográficos relacionados con la deserción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d484b",
   "metadata": {},
   "source": [
    "\n",
    "2. **Longitud de la cuenta (account_length)**: Representa la duración de la relación del cliente con la compañía en días. Esto puede ser un indicador de fidelidad, ya que clientes con cuentas más antiguas tienden a ser más leales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce1a05",
   "metadata": {},
   "source": [
    "\n",
    "3. **Código de área (area_code)**: El código de área asociado con el número telefónico del cliente. Aunque no es un factor directo de deserción, podría servir para segmentar geográficamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39041c8",
   "metadata": {},
   "source": [
    "\n",
    "4. **Plan internacional (international_plan)**: Indica si el cliente tiene contratado un plan de llamadas internacionales. Clientes que no necesitan este plan pueden cambiar de proveedor si no ven valor en los servicios ofrecidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b00b1b1",
   "metadata": {},
   "source": [
    "\n",
    "5. **Plan de correo de voz (voice_mail_plan)**: Indica si el cliente tiene un plan de correo de voz. La falta de servicios adicionales como este podría estar relacionada con la insatisfacción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475b94e6",
   "metadata": {},
   "source": [
    "\n",
    "6. **Número de mensajes de correo de voz (number_vmail_messages)**: Número de mensajes de voz que el cliente ha recibido. Esto da una idea del uso que el cliente hace del plan de correo de voz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7387e9",
   "metadata": {},
   "source": [
    "\n",
    "7. **Minutos totales durante el día (total_day_minutes)**: Cantidad de minutos que el cliente usa el servicio durante el día. Un uso elevado o bajo puede tener relación con la decisión de cancelar el servicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a7574",
   "metadata": {},
   "source": [
    "\n",
    "8. **Número total de llamadas durante el día (total_day_calls)**: Cantidad de llamadas realizadas por el cliente durante el día. El volumen de llamadas puede ser un indicador del uso general del servicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698afbb",
   "metadata": {},
   "source": [
    "\n",
    "9. **Cargos totales durante el día (total_day_charge)**: Los cargos totales generados por las llamadas diurnas. Un aumento en los cargos sin un aumento proporcional en el uso podría generar insatisfacción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692d3f1",
   "metadata": {},
   "source": [
    "\n",
    "10. **Minutos totales durante la tarde (total_eve_minutes)**: Minutos utilizados durante la tarde, otra ventana de tiempo importante para medir el uso del servicio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdceb0aa",
   "metadata": {},
   "source": [
    "\n",
    "11. **Número de llamadas durante la tarde (total_eve_calls)**: Número de llamadas realizadas en la tarde, puede influir en la experiencia del cliente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f1074",
   "metadata": {},
   "source": [
    "\n",
    "12. **Cargos totales durante la tarde (total_eve_charge)**: Los cargos asociados a las llamadas realizadas durante la tarde.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf051fc4",
   "metadata": {},
   "source": [
    "\n",
    "13. **Minutos totales durante la noche (total_night_minutes)**: Minutos totales utilizados durante la noche. Este es otro período importante para medir el uso de los servicios de telecomunicaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1233037",
   "metadata": {},
   "source": [
    "\n",
    "14. **Número de llamadas durante la noche (total_night_calls)**: Número de llamadas realizadas durante la noche.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae8764b",
   "metadata": {},
   "source": [
    "\n",
    "15. **Cargos totales durante la noche (total_night_charge)**: Cargos generados por las llamadas nocturnas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47aa4c6",
   "metadata": {},
   "source": [
    "\n",
    "16. **Minutos internacionales totales (total_intl_minutes)**: Minutos que el cliente ha utilizado para llamadas internacionales. Los clientes con un plan internacional probablemente tendrán un mayor uso en esta categoría.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12245f96",
   "metadata": {},
   "source": [
    "\n",
    "17. **Número de llamadas internacionales (total_intl_calls)**: Cantidad de llamadas internacionales que ha realizado el cliente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc53072a",
   "metadata": {},
   "source": [
    "\n",
    "18. **Cargos internacionales totales (total_intl_charge)**: Cargos generados por las llamadas internacionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fc117",
   "metadata": {},
   "source": [
    "\n",
    "19. **Número de llamadas al servicio de atención al cliente (number_customer_service_calls)**: Número de veces que el cliente ha llamado al servicio de atención al cliente. Un número elevado de llamadas puede indicar problemas o insatisfacción, y por tanto estar correlacionado con la deserción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67b42f6",
   "metadata": {},
   "source": [
    "\n",
    "20. **Deserción (churn)**: Es la variable objetivo. Indica si el cliente ha abandonado la compañía o no (1 = Sí, 0 = No). El objetivo de muchos modelos de machine learning es predecir esta variable utilizando las demás variables como características.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9b5b7b",
   "metadata": {},
   "source": [
    "\n",
    "### Significado del dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0ef2cc",
   "metadata": {},
   "source": [
    "Este dataset es fundamental para el análisis de **churn** (deserción), que es un problema crítico para empresas que prestan servicios recurrentes, como telecomunicaciones, bancos, plataformas de suscripción, entre otros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daed9802",
   "metadata": {},
   "source": [
    "El objetivo principal es usar estas variables para entrenar modelos de **machine learning** que permitan predecir si un cliente está en riesgo de abandonar la empresa, de manera que las organizaciones puedan implementar estrategias de retención proactivas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d05cf7",
   "metadata": {},
   "source": [
    "\n",
    "Este tipo de análisis es común en proyectos de **ciencia de datos aplicada a la gestión empresarial**, donde se busca no solo \n",
    "* identificar patrones, sino también \n",
    "* crear perfiles de clientes en riesgo, \n",
    "* entender las razones del abandono, y \n",
    "* generar estrategias para mejorar la satisfacción y fidelización del cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da610dd3",
   "metadata": {},
   "source": [
    "[Video de apoyo a la contextualización del problema](https://www.youtube.com/watch?v=nHQArPJWx24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e828e96c",
   "metadata": {},
   "source": [
    "# Obtención de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3c1f5",
   "metadata": {},
   "source": [
    "Tenemos dos opciones para obtención de datos:\n",
    "1. Obtención local \n",
    "2. Obtención desde url "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd3e1bd",
   "metadata": {},
   "source": [
    "* Favor leer sobre la función `pandas.read_csv()` [aquí](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "* Favor leer sobre la función `pandas.read_excel()` [aquí](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239427f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "url = \"https://raw.githubusercontent.com/marco-canas/extension/refs/heads/main/taller_g_lideres/6_churn/Telco%20BigML%20Churn%205000.csv\"\n",
    "df= pd.read_csv(url)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexamos desde 1 a los clientes \n",
    "import numpy as np \n",
    "df.index = np.arange(1, 5000+1) \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bc8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ontención de los nombres de los atributos o keys\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar las columnas del DataFrame a español\n",
    "# Esta estrategia de renombre es por reasignación \n",
    "# Vea la estrategia a través de la función pandas.rename()\n",
    "\n",
    "df.columns = [\n",
    "    'Estado', 'LongitudCuenta', 'CodigoArea', 'PlanInternacional', \n",
    "    'PlanCorreoVoz', 'NumeroMensajesCorreoVoz', 'MinutosDiaTotales', \n",
    "    'LlamadasDiaTotales', 'CargosDiaTotales', 'MinutosTardeTotales', \n",
    "    'LlamadasTardeTotales', 'CargosTardeTotales', 'MinutosNocheTotales', \n",
    "    'LlamadasNocheTotales', 'CargosNocheTotales', 'MinInternacTotales', \n",
    "    'LlamadasInterncTotales', 'CargosInternacTotales', \n",
    "    'NumeroLlamadasAtencionClientes', 'Desercion'\n",
    "]\n",
    "# El método pandas.DataFrame.rename(columns = {}) para renombrar de manera selectiva  \n",
    "\n",
    "# Verificar los cambios\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d221d",
   "metadata": {},
   "source": [
    "# Take a Quick Look at the Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resumen de las variables categóricas y numéricas \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a493f",
   "metadata": {},
   "source": [
    "## Inferencias de la utilización del método `pandas.info()`\n",
    "\n",
    "1. No hay atributos con datos faltantes. De donde se infiere que no será necesario hacer procesamiento de datos faltantes. \n",
    "2. Hay cuatro atributos predictores categóricos sin codificar.\n",
    "3. La variable objetivo es categórica y está sin codificar. (Codificar es representar sus valores de manera numérica) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c340d5",
   "metadata": {},
   "source": [
    "# Lo que seguiremos en la metodología de modelación  \n",
    "\n",
    "1. Discover and visualize the data to gain insights.\n",
    "2. Prepare the data for Machine Learning algorithms.\n",
    "3. Select a model and train it.\n",
    "4. Fine-tune your model.\n",
    "5. Present your solution.\n",
    "6. Launch, monitor, and maintain your system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5189c451",
   "metadata": {},
   "source": [
    "# Visualización de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed83b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficación personalizada de variables categóricas \n",
    "def grafico_de_barras(datos, atributo, nombre_de_los_datos):\n",
    "    '''\n",
    "    INPUT: \n",
    "        datos: una serie de pandas\n",
    "        atributo: el atributo que se quiere graficar, que va a ser una cadena de caracteres. \n",
    "        nombre_de_los_datos: como una cadena de caracteres. \n",
    "    '''\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "    # Crear figura y dos subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Gráfico de barras en el subplot de la izquierda\n",
    "    ax1.set_title(f'Balance de {atributo} de clientes en el dataset {nombre_de_los_datos}')\n",
    "    ax1.set_xlabel(f'{atributo}')\n",
    "    ax1.set_ylabel('Número de clientes')\n",
    "    bar_colors = ['tab:green', 'tab:red', 'tab:pink']\n",
    "    ax1.bar(x=datos[atributo].value_counts().index, height=datos[atributo].value_counts().values, \n",
    "            edgecolor='black', color=bar_colors)\n",
    "    ax1.grid(alpha=0.3)\n",
    "\n",
    "    # Diagrama de pastel en el subplot de la derecha\n",
    "    ax2.pie(x=datos[atributo].value_counts().values, labels=datos[atributo].value_counts().index, \n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    ax2.set_title(f'Porcentaje de {atributo} de clientes')\n",
    "\n",
    "    # Guardar la figura en archivo\n",
    "    plt.savefig(f\"de_donde_vienen_los_cliente.jpg\")\n",
    "    plt.show()\n",
    "\n",
    "    # Retornar conteo de valores\n",
    "    return datos[atributo].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c87c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_de_barras(datos = df, atributo = 'Estado', nombre_de_los_datos='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992aa3e2",
   "metadata": {},
   "source": [
    "Debemos utilizar la técnica Target Encoding que es para variables categóricas no ordinales que tienen muchas subcategorías. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.Estado.value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845d9ee",
   "metadata": {},
   "source": [
    "## Inferencias de esta gráfico de barras  \n",
    "\n",
    "La variable de `Estado` tiene un número de valores muy grande, lo que hace necesario de que su codificación sea diferente a la codificación ordinaria y a la codificación one-hot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea90ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_de_barras(datos = df, atributo = 'CodigoArea', nombre_de_los_datos='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4530a",
   "metadata": {},
   "source": [
    "## Inferencias de la visualización de esta variable categórica  \n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_de_barras(atributo = 'PlanInternacional', datos = df, nombre_de_los_datos='df') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573eff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grafico_de_barras(atributo = 'PlanCorreoVoz',  datos = df, nombre_de_los_datos='df')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44cdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e033753",
   "metadata": {},
   "source": [
    "### [Como cambiar la familia indexante y como guargar gráficos](https://www.youtube.com/watch?v=SaxAFtDh7Qk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ef594",
   "metadata": {},
   "source": [
    "# Observemos a la variable objetivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da0191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_de_barras(atributo = 'Desercion',  datos = df, nombre_de_los_datos='Análisis de Deserción')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25f602",
   "metadata": {},
   "source": [
    "# Visualización tabular de variables numéricas discretas y continuas \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5862f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de variables aleatorias numéricas discretas y continuas \n",
    "df.describe(include='all')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12858848",
   "metadata": {},
   "source": [
    "## Inferencias \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc69cb",
   "metadata": {},
   "source": [
    "# Visualización Gráfica de variables cuantitativas usando Pandas y matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de histogramas\n",
    "import matplotlib.pyplot as plt \n",
    "df.hist(bins = 50, figsize=(20,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffb599",
   "metadata": {},
   "source": [
    "## Conclusiones o Inferencias de la visualización de variables cuantitativas continuas  \n",
    "\n",
    "1. Casi todas las variables numéricas predictoras, tiene un distribución acampanada  \n",
    "2. Los rangos de estos variables son de valores distante y\n",
    "3. los valores de algunas de las variables son muy grandes o otros muy pequeños.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d934e2f2",
   "metadata": {},
   "source": [
    "La distribución acampanada de los atributos predictores, que típicamente se refiere a una **distribución normal (o gaussiana)**, influye en el desempeño de los modelos de machine learning de diversas maneras, dependiendo del tipo de modelo y del contexto de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba11a60",
   "metadata": {},
   "source": [
    " Aquí algunos puntos clave:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a8435",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **Modelos Lineales y Estadísticos**:\n",
    "   - **Regresión lineal** y otros modelos estadísticos que asumen relaciones lineales entre las variables suelen beneficiarse cuando los predictores tienen distribuciones normales. Esto se debe a que la normalidad en los predictores favorece la convergencia de los algoritmos de optimización y garantiza que los residuos (errores) tengan una distribución más predecible, lo que mejora las inferencias y la interpretación del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4865e",
   "metadata": {},
   "source": [
    "   - Además, la normalidad de los predictores minimiza el **sesgo** y la **varianza**, lo que puede llevar a un mejor ajuste del modelo y una mayor robustez frente a ruido en los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8f737e",
   "metadata": {},
   "source": [
    "\n",
    "### 2. **Algoritmos Basados en Distancia**:\n",
    "   - Modelos como el **k-nearest neighbors (k-NN)** o **máquinas de soporte vectorial (SVM)** con kernels lineales tienden a desempeñarse mejor cuando las variables tienen distribuciones simétricas y sin sesgos. Una distribución normal permite que las distancias entre puntos de datos se calculen de manera más consistente, lo que facilita la separación o clasificación de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4975c1",
   "metadata": {},
   "source": [
    "   - Si los atributos tienen distribuciones muy desbalanceadas o sesgadas, estos modelos podrían sobreponderar ciertas características, afectando negativamente su desempeño.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33db45",
   "metadata": {},
   "source": [
    "\n",
    "### 3. **Redes Neuronales y Modelos Complejos**:\n",
    "   - Aunque **redes neuronales** y otros algoritmos más complejos como **árboles de decisión** o **random forests** no necesariamente requieren que los datos sean normalmente distribuidos, una distribución acampanada puede facilitar el entrenamiento porque **evita valores extremos** que pueden distorsionar el aprendizaje.\n",
    "   - Sin embargo, estos modelos son más robustos frente a la no normalidad de los datos, ya que no dependen de suposiciones estrictas sobre la distribución de los predictores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b8941",
   "metadata": {},
   "source": [
    "\n",
    "### 4. **Normalización y Estandarización**:\n",
    "   - Incluso si un predictor no sigue una distribución acampanada, los pasos de **normalización** (escala [0,1]) o **estandarización** (centrado en 0, con desviación estándar 1) pueden ayudar a mejorar el rendimiento de muchos algoritmos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa3948",
   "metadata": {},
   "source": [
    "La estandarización convierte los datos en algo más cercano a una distribución normal, lo cual es particularmente útil para algoritmos como **regresión logística**, **SVM**, y **algoritmos basados en gradiente**.\n",
    "   - Las distribuciones normales son ideales para estos procesos porque facilitan la transformación a escalas comparables sin la necesidad de grandes ajustes o transformaciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50774e8b",
   "metadata": {},
   "source": [
    "\n",
    "### 5. **Ruido y Outliers**:\n",
    "   - Una distribución acampanada suele implicar una menor presencia de **outliers** (valores atípicos), lo cual es beneficioso para el rendimiento de los modelos de machine learning. Los outliers pueden desestabilizar muchos algoritmos, especialmente los que dependen de cálculos de distancia o que son sensibles a los valores extremos (como la regresión lineal). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d03c1a",
   "metadata": {},
   "source": [
    "\n",
    "### Resumen:\n",
    "En general, una distribución acampanada (normal) de los atributos predictores puede mejorar el desempeño de los modelos de machine learning, especialmente aquellos que dependen de suposiciones estadísticas sobre los datos o que son sensibles a la escala y la varianza. Para modelos complejos, aunque no es un requisito estricto, puede simplificar el proceso de entrenamiento y mejorar la eficiencia de los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a8b6c",
   "metadata": {},
   "source": [
    "# Seleccionar el conjunto de prueba o testeo con muestreo puramente aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3455ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=513, stratify=None)\n",
    "\n",
    "# Tarea: Lea sobre la función `sklearn.train_test_split()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ea79c",
   "metadata": {},
   "source": [
    "# Imagen de un train set y un test set \n",
    "\n",
    "<img src = 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRs2aoO8J1-yzMcCUqY8t_zD1PZ5vbqD0e4LQ&s'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificación de la mezcla aleatoria\n",
    "len(train_set), len(test_set), len(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación gráfica del muestreo aleatorio\n",
    "\n",
    "grafico_de_barras(datos = train_set, atributo = 'Desercion', nombre_de_los_datos='train_set') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182d5be",
   "metadata": {},
   "source": [
    "# Muestreo aleatorio  y estratificado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec4e336",
   "metadata": {},
   "source": [
    "<img src = 'https://tesisdeceroa100.com/wp-content/uploads/2020/01/muestreo-estatificado-1-1.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb17ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size=0.2, random_state=513, stratify=df['Desercion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef88712",
   "metadata": {},
   "outputs": [],
   "source": [
    "grafico_de_barras(datos = test_set, atributo = 'Desercion', nombre_de_los_datos='train_set') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d828798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Desercion'].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b6982",
   "metadata": {},
   "source": [
    "# Codificación de la variable objetivo  en el conjunto de entrenamiento y el conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b876ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['Desercion'] = (train_set['Desercion'] == 'yes')*1\n",
    "test_set['Desercion'] = (test_set['Desercion'] == 'yes')*1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c28d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifica que si codificó la variable objetivo \n",
    "\n",
    "train_set.Desercion.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d1914",
   "metadata": {},
   "source": [
    "# Construir una lista con los atributos predictores categóricos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b0a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea, consulte sobre las propiedades de la función remove() para listas de python. Esta función modifica la lista in-place, \n",
    "# es decir, modifica la lista original sin devolver ningín valor \n",
    "atributos_categoricos = df.select_dtypes(include='object')\n",
    "atributos_categoricos = list(atributos_categoricos)  # Convertir a lista si no lo es\n",
    "atributos_categoricos.remove('Desercion')  # Eliminar 'Desercion' de la lista\n",
    "atributos_categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df49faaa",
   "metadata": {},
   "source": [
    "# Hacer una copia del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_set.copy()\n",
    "df_test = test_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d6686",
   "metadata": {},
   "source": [
    "# Análisis de correlaciones  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Desercion.value_counts()/len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b49e25",
   "metadata": {},
   "source": [
    "# La correlación de punto biserial "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a57b0c",
   "metadata": {},
   "source": [
    "La **correlación de punto biserial** es una técnica que mide la relación entre una variable cuantitativa continua y una variable binaria (categórica con dos posibles valores, como 0 y 1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908764a",
   "metadata": {},
   "source": [
    "Se puede considerar como una forma especial de la correlación de Pearson, adaptada para variables binarias. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe177391",
   "metadata": {},
   "source": [
    "\n",
    "### Fórmula de la correlación de punto biserial\n",
    "\n",
    "La fórmula es:\n",
    "\n",
    "$$\n",
    "r_{pb} = \\frac{M_1 - M_0}{s} \\sqrt{\\frac{p(1 - p)}{n}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a01973",
   "metadata": {},
   "source": [
    "\n",
    "Donde:\n",
    "- $M_1$ es la media de la variable cuantitativa para los casos donde la variable binaria es 1.\n",
    "- $M_0$ es la media de la variable cuantitativa para los casos donde la variable binaria es 0.\n",
    "- $s$ es la desviación estándar total de la variable cuantitativa.\n",
    "- $p$ es la proporción de casos en la categoría 1.\n",
    "- $n$ es el tamaño total de la muestra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a49488",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretación\n",
    "El coeficiente de correlación de punto biserial $r_{pb}$ oscila entre -1 y 1:\n",
    "- Un valor cercano a 1 indica una fuerte correlación positiva.\n",
    "- Un valor cercano a -1 indica una fuerte correlación negativa.\n",
    "- Un valor cercano a 0 indica una correlación débil o nula.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd7c65",
   "metadata": {},
   "source": [
    "\n",
    "### Implementación en Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b226d510",
   "metadata": {},
   "source": [
    "\n",
    "En Python, puedes implementar la correlación de punto biserial usando bibliotecas como `scipy` o `pandas` para manejar los datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8cc6f",
   "metadata": {},
   "source": [
    "A continuación te doy un ejemplo paso a paso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc15d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(atributos_categoricos, axis = 1).columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76527b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_numericos = df_train.select_dtypes(include = ['float64', 'int64'])\n",
    "atributos_numericos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee517e31",
   "metadata": {},
   "source": [
    "\n",
    "Luego, puedes usar el siguiente código:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2903ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Seleccionamos las variables numéricas\n",
    "atributos_numericos = df_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Inicializamos un diccionario para almacenar las correlaciones de punto biserial\n",
    "correlaciones = {}\n",
    "p_valores = {}\n",
    "\n",
    "# Iteramos sobre cada atributo numérico para calcular la correlación de punto biserial\n",
    "for atributo in atributos_numericos:\n",
    "    corr_punto_biserial, p_valor = stats.pointbiserialr(df_train['Desercion'], df_train[atributo])\n",
    "    correlaciones[atributo] = corr_punto_biserial\n",
    "    p_valores[atributo] = p_valor\n",
    "    print(f\"Correlación de punto biserial con {atributo}: {corr_punto_biserial}\")\n",
    "    \n",
    "    if p_valor < 0.05:\n",
    "        print(f\"Valor p: {p_valor}, altamente significativa desde el punto de vista estadístico.\")\n",
    "    else:\n",
    "        print(f\"Valor p: {p_valor}, no significativa desde el punto de vista estadístico.\")\n",
    "\n",
    "# Convertimos el diccionario de correlaciones en un DataFrame para visualizarlo\n",
    "correlaciones_df = pd.DataFrame(list(correlaciones.items()), columns=['Variable', 'Correlacion'])\n",
    "\n",
    "# Generamos un mapa de calor con las correlaciones\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlaciones_df.set_index('Variable').T, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Mapa de calor de las correlaciones de punto biserial')\n",
    "#plt.savefig('/mapa_correlaciones.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1684cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlaciones_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c690508c",
   "metadata": {},
   "source": [
    "<img src = 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/600px-Correlation_examples2.svg.png' width = 600>\n",
    "\n",
    "Fuente: Imagen pública de Wikipedia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53876c52",
   "metadata": {},
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba67062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from pandas.plotting import scatter_matrix\n",
    "attributes_parte_1 = [elemento for elemento in list(df.columns) if elemento not in atributos_categoricos][:4]\n",
    "attributes_parte_2 = [elemento for elemento in list(df.columns) if elemento not in atributos_categoricos][4:8]\n",
    "attributes_parte_3 = [elemento for elemento in list(df.columns) if elemento not in atributos_categoricos][8:12]       \n",
    "attributes_parte_4 = [elemento for elemento in list(df.columns) if elemento not in atributos_categoricos][12:]\n",
    "\n",
    "scatter_matrix(df[attributes_parte_1], figsize=(14, 10))\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ad45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[attributes_parte_1].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d47e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(df[attributes_parte_2], figsize=(14, 10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(df[attributes_parte_3], figsize=(14, 10))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(df[attributes_parte_4], figsize=(14, 10))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae4df7",
   "metadata": {},
   "source": [
    "# Diagrama de dispersión individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444bb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\", x=df_train.columns[7], y=df_train.columns[8], alpha=0.1, \\\n",
    "    title = f'Grafico de {df_train.columns[7]} vs {df_train.columns[8]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230e998",
   "metadata": {},
   "source": [
    "## Recomendación: Experimente con combinación de atributos \n",
    "\n",
    "Ejemplo: Página 65 de Geron. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31afb20f",
   "metadata": {},
   "source": [
    "# Preparemos ahora los datos para los algoritmos de machine learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d37a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en predictores y etiquetas.  \n",
    "\n",
    "df_train_atributos = df_train.drop(\"Desercion\", axis=1)\n",
    "df_train_labels = df_train[\"Desercion\"].copy()\n",
    "df_test_atributos = df_test.drop(\"Desercion\", axis=1)\n",
    "df_test_labels = df_test[\"Desercion\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b779824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_atributos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e19f24",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7e2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n",
    "#housing.drop(\"total_bedrooms\", axis=1) # option 2\n",
    "#median = housing[\"total_bedrooms\"].median() # option 3\n",
    "#housing[\"total_bedrooms\"].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9649bf81",
   "metadata": {},
   "source": [
    "# Tratamiento de datos categóricos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b00c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapaconceptual de clasificación de tipos de variables y tipos de codificación adecuada \n",
    "\n",
    "# mapa conceptual para cada clase  \n",
    "from graphviz import Digraph\n",
    "\n",
    "# Crear un nuevo grafo dirigido\n",
    "dot = Digraph()\n",
    "\n",
    "# Añadir nodos y relaciones al grafo\n",
    "main_concept = 'Codificacion Variables Categoricas'\n",
    "dot.node('A', main_concept)\n",
    "dot.node('B', 'Variables categóricas ordinales')\n",
    "dot.node('C', 'Variables categóricas no ordinales')\n",
    "dot.node('D', 'No ordinales de pocas subcategorias')\n",
    "dot.node('E', 'No ordinales de muchas subcategorias')\n",
    "\n",
    "dot.edges(['AB', 'AC', 'CD', 'CE']) \n",
    "\n",
    "# Guardar el grafo como un archivo de imagen\n",
    "dot.render(filename=main_concept, format='png', cleanup=True,\\\n",
    "    directory='C:/Users/marco/Documentos/extension/taller_g_lideres/6_pactica_ml/images/')\n",
    "\n",
    "dot.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9da18a",
   "metadata": {},
   "source": [
    "Ya codificamos la variable objetivo, pero falta codificar las demás variables categóricas que son predictivas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "atributos_categoricos = df.select_dtypes(include='object').columns\n",
    "df_cat_encoded = ordinal_encoder.fit_transform(df[atributos_categoricos])\n",
    "df_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66f21e",
   "metadata": {},
   "source": [
    "La clase `OrdinalEncoder()` de **scikit-learn** es aplicable cuando necesitas convertir variables categóricas en **valores numéricos ordinales** (valores enteros) que reflejan un **orden natural** entre las categorías. Es útil cuando trabajas con características categóricas que tienen un orden intrínseco y necesitas que los modelos de machine learning interpreten ese orden. A continuación te explico cuándo es aplicable y cómo se usa:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7e5b2",
   "metadata": {},
   "source": [
    "\n",
    "### Aplicabilidad de `OrdinalEncoder()`\n",
    "1. **Categorías con Orden Natural**:\n",
    "   - Se utiliza cuando las categorías tienen un **orden jerárquico o natural**. Por ejemplo, si tienes una característica como `nivel de educación`, donde las categorías son:\n",
    "     - \"Primaria\", \"Secundaria\", \"Pregrado\", \"Postgrado\".\n",
    "   - En este caso, hay una relación intrínseca entre los niveles, y se espera que esta jerarquía sea capturada por el modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb752530",
   "metadata": {},
   "source": [
    "\n",
    "2. **Modelos que No Aceptan Datos Categóricos Directos**:\n",
    "   - Muchos modelos de machine learning (como **regresión logística**, **árboles de decisión**, **SVM**) no pueden trabajar directamente con datos categóricos. Por lo tanto, `OrdinalEncoder()` es útil para convertir esas categorías en valores numéricos que los modelos puedan usar.\n",
    "\n",
    "3. **Datos de Encuestas o Escalas de Clasificación**:\n",
    "   - Es útil cuando trabajas con datos que provienen de encuestas o clasificaciones ordinales. Ejemplos comunes son:\n",
    "     - Escalas de satisfacción: \"Muy insatisfecho\", \"Insatisfecho\", \"Neutral\", \"Satisfecho\", \"Muy satisfecho\".\n",
    "     - Clasificación de productos: \"Baja calidad\", \"Media calidad\", \"Alta calidad\".\n",
    "\n",
    "4. **Cuando no necesitas codificación one-hot**:\n",
    "   - Si no necesitas crear variables binarias para cada categoría (como lo harías con `OneHotEncoder()`), y en su lugar prefieres mantener una representación compacta y ordinal de las categorías, `OrdinalEncoder()` es adecuado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372465f0",
   "metadata": {},
   "source": [
    "\n",
    "### Cuándo no es aplicable:\n",
    "- **Categorías sin orden intrínseco**: Si las categorías no tienen un orden natural, usar `OrdinalEncoder()` no es adecuado porque asignar números a categorías sin orden puede inducir al modelo a interpretar incorrectamente esas relaciones. En este caso, sería mejor usar **OneHotEncoder()**. Ejemplos de categorías sin orden:\n",
    "  - Colores: \"Rojo\", \"Verde\", \"Azul\".\n",
    "  - Géneros de música: \"Rock\", \"Jazz\", \"Pop\".\n",
    "  \n",
    "- **Modelos que no dependen de orden**: Algunos modelos, como **árboles de decisión** o **random forests**, no dependen del orden de los valores numéricos. Por lo tanto, `OrdinalEncoder()` puede no ser la mejor opción y `OneHotEncoder()` puede funcionar igual o mejor.\n",
    "\n",
    "### Ejemplo de uso de `OrdinalEncoder()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ab952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar según el criterio de orden de científico de datos\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Ejemplo de categorías con orden creciente de escolaridad\n",
    "categorias = np.array([['Primaria'], ['Secundaria'], ['Pregrado'], ['Postgrado']])\n",
    "\n",
    "# Crear el objeto OrdinalEncoder con el orden correcto de las categorías\n",
    "encoder = OrdinalEncoder(categories=[['Primaria', 'Secundaria', 'Pregrado', 'Postgrado']])\n",
    "\n",
    "# Aplicar el codificador a los datos categóricos\n",
    "categorias_codificadas = encoder.fit_transform(categorias)\n",
    "\n",
    "print(categorias_codificadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d06e01",
   "metadata": {},
   "source": [
    "\n",
    "En este ejemplo, las categorías se convertirán a valores numéricos ordenados, como:\n",
    "- \"Primaria\" → 0\n",
    "- \"Secundaria\" → 1\n",
    "- \"Pregrado\" → 2\n",
    "- \"Postgrado\" → 3\n",
    "\n",
    "### Resumen:\n",
    "`OrdinalEncoder()` es aplicable cuando las características categóricas tienen un orden natural y necesitas que el modelo de machine learning lo interprete. No es adecuado para categorías sin orden, donde es mejor usar otras técnicas de codificación como `OneHotEncoder()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaaf94",
   "metadata": {},
   "source": [
    "# La Codificación One-Hot Encoding  \n",
    "La **codificación One-Hot (One-Hot Encoding)** es útil en las siguientes situaciones:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f43fb",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **Modelos de Machine Learning que no manejan bien datos categóricos**\n",
    "   - **Algoritmos que requieren valores numéricos**: Algunos algoritmos de aprendizaje automático, como regresión logística, redes neuronales, y k-means, no pueden procesar directamente variables categóricas. **One-Hot Encoding** convierte las categorías en columnas binarias (0 o 1), permitiendo que el algoritmo maneje variables categóricas de manera eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe639f51",
   "metadata": {},
   "source": [
    "\n",
    "### 2. **Cuando no hay un orden implícito en las categorías**\n",
    "   - **Categorías sin jerarquía**: One-Hot Encoding es útil cuando las categorías no tienen un orden inherente o jerarquía. Por ejemplo, las variables como \"color\" (rojo, azul, verde) o \"ciudad\" (Bogotá, Medellín, Cali) son **nominales** (sin orden). En estos casos, codificar las categorías como números ordinales podría inducir relaciones falsas, ya que el modelo podría interpretar jerarquías inexistentes.\n",
    "\n",
    "### 3. **Evitar suposiciones incorrectas sobre las relaciones entre categorías**\n",
    "   - **Eliminar el riesgo de suposiciones de orden**: Usar One-Hot Encoding evita que los modelos asuman que hay una relación lineal o jerárquica entre categorías, lo que puede suceder si se usa una codificación ordinal.\n",
    "\n",
    "### 4. **Para modelos lineales o redes neuronales**\n",
    "   - **Mejor rendimiento con datos binarios**: Algoritmos como redes neuronales o modelos de regresión lineal suelen funcionar mejor con datos en formato binario (0/1) debido a cómo procesan las entradas. La codificación One-Hot permite que estas técnicas identifiquen patrones más fácilmente en datos categóricos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968487a2",
   "metadata": {},
   "source": [
    "\n",
    "### 5. **Para trabajar con grandes datasets con muchas categorías**\n",
    "   - **Categorías en datasets grandes**: En grandes datasets con muchas categorías pero con una cantidad limitada de categorías únicas por columna, One-Hot Encoding puede ser eficaz para evitar los problemas de interpretación y mejorar el rendimiento en tareas como clasificación o regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a1cfd",
   "metadata": {},
   "source": [
    "\n",
    "### Ejemplo de cuándo usar One-Hot Encoding:\n",
    "- Si tienes una columna **\"Género\"** con valores categóricos [\"Mujer\", \"Hombre\"], la codificación ordinal podría asignar [0, 1], lo que implicaría un orden entre los valores, aunque no lo haya. Con One-Hot Encoding, crearías dos columnas binarias, una para \"Mujer\" y otra para \"Hombre\", eliminando cualquier interpretación errónea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8941035f",
   "metadata": {},
   "source": [
    "\n",
    "### Limitación:\n",
    "- **One-Hot Encoding aumenta la dimensionalidad**: Si tienes muchas categorías diferentes, cada categoría se convertirá en una columna, lo que puede aumentar significativamente el tamaño del dataset y afectar el rendimiento del modelo. Esto es especialmente problemático si las categorías tienen muchas clases únicas (por ejemplo, miles de ciudades). En estos casos, técnicas como **Target Encoding** o **Hashing** pueden ser más eficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176eddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CodigoArea.value_counts() # el código de área es una variable categórica no ordinal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "df_train_cat_no_ordinal = df_train[['CodigoArea']]\n",
    "X_cat_1hot = cat_encoder.fit_transform(df_train_cat_no_ordinal)\n",
    "X_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat_1hot = df_cat_1hot.toarray()\n",
    "X_cat_1hot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir en un dataframe a esta variable codificada \n",
    "valores_CodigoArea = df_train.CodigoArea.value_counts().index\n",
    "df_cat_1hot = pd.DataFrame(X_cat_1hot, columns = valores_CodigoArea)\n",
    "df_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9bdfa",
   "metadata": {},
   "source": [
    "# Otra variable categórica de codificación interesante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Estado.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3a441",
   "metadata": {},
   "source": [
    "# Técnica Target Encoding  y la técnica Hashing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1df9e1",
   "metadata": {},
   "source": [
    "Cuando se trabaja con **variables categóricas no ordinales** (sin un orden natural) y con un gran número de subcategorías, es importante elegir la técnica adecuada para codificarlas en un formato numérico que pueda ser procesado por los modelos de machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbf33d",
   "metadata": {},
   "source": [
    "Estas son dos técnicas avanzadas para abordar este desafío: **Target Encoding** y **Hashing**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60856b28",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **Target Encoding (Codificación Basada en el Objetivo)**\n",
    "\n",
    "#### Descripción:\n",
    "La técnica de **Target Encoding** asigna un valor numérico a cada categoría basado en la **media del objetivo** (target) o la **variable de salida** que estás tratando de predecir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a46b8d",
   "metadata": {},
   "source": [
    "Esto significa que la codificación toma en cuenta la relación entre una categoría y el valor de la variable objetivo. Es especialmente útil en problemas de **regresión** y **clasificación**, donde se utiliza el promedio de la variable objetivo de los registros asociados con cada categoría.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f98f86",
   "metadata": {},
   "source": [
    "\n",
    "#### Funcionamiento:\n",
    "- En un problema de **regresión**, se calcula el promedio del valor objetivo (target) para cada categoría. Luego, esa media se usa para reemplazar la categoría.\n",
    "- En un problema de **clasificación**, se utiliza la tasa de incidencia (la proporción de veces que una clase aparece) para codificar las categorías.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd916070",
   "metadata": {},
   "source": [
    "#### Ejemplo:\n",
    "Supongamos que tienes una variable categórica \"Ciudad\" y la variable objetivo es el precio promedio de las casas en cada ciudad. Con Target Encoding, la categoría \"Ciudad A\" se codificaría con el promedio de precios de casas en \"Ciudad A\", \"Ciudad B\" con el promedio en \"Ciudad B\", etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484ea0df",
   "metadata": {},
   "source": [
    "\n",
    "##### Ventajas:\n",
    "- **Captura relaciones estadísticas** entre las categorías y el objetivo, lo que puede mejorar el rendimiento del modelo al proporcionar una codificación más informada.\n",
    "- **Reduce la dimensionalidad**, ya que no crea muchas columnas adicionales como ocurre con la codificación one-hot.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd0a1a",
   "metadata": {},
   "source": [
    "##### Desventajas:\n",
    "- **Riesgo de sobreajuste**: Como la codificación está basada en la variable objetivo, si no se implementa correctamente (sin validación cruzada), podría llevar a sobreajuste del modelo a los datos de entrenamiento.\n",
    "- **Bias en categorías raras**: Para categorías con pocas observaciones, las estimaciones pueden ser ruidosas o poco confiables.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af63ba3",
   "metadata": {},
   "source": [
    "##### Ejemplo en Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a1858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Datos de ejemplo\n",
    "df = pd.DataFrame({\n",
    "    'Ciudad': ['A', 'B', 'A', 'C', 'B', 'C', 'A'],\n",
    "    'Precio': [200, 300, 200, 300, 400, 320, 200]\n",
    "})\n",
    "\n",
    "# Definir el TargetEncoder sin suavizado\n",
    "encoder = TargetEncoder(smoothing=0, min_samples_leaf=1)\n",
    "\n",
    "# Aplicar el codificador a la columna \"Ciudad\" usando la variable objetivo \"Precio\"\n",
    "df['Ciudad_codificada'] = encoder.fit_transform(df['Ciudad'], df['Precio'])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d6a1b5",
   "metadata": {},
   "source": [
    "\n",
    "### 2. **Hashing (Hashing Trick)**\n",
    "\n",
    "#### Descripción:\n",
    "La técnica de **Hashing** (o **Hashing Trick**) convierte las categorías en valores numéricos aplicando una **función hash**. Esto significa que se aplica una función matemática que toma cada categoría y la transforma en un valor entero. Este enfoque es muy eficiente cuando tienes un número extremadamente alto de categorías, ya que no requiere construir explícitamente un diccionario de mapeo de categorías a números.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1a54c",
   "metadata": {},
   "source": [
    "\n",
    "#### Funcionamiento:\n",
    "- El **Hashing Trick** asigna cada categoría a una posición en un vector de tamaño fijo (predefinido). Las categorías que colisionan (es decir, que el hash de diferentes categorías resulta en el mismo valor) comparten la misma posición.\n",
    "- Se elige un número de **dimensiones (k)**, que define el tamaño del espacio donde se mapean las categorías. A partir de aquí, cada categoría es transformada en su valor hash, y este valor se usa para construir la representación numérica en un espacio de menor dimensión.\n",
    "\n",
    "#### Ejemplo:\n",
    "Supón que tienes 1 millón de categorías en una columna. En lugar de codificarlas todas individualmente (lo que consumiría mucha memoria), aplicas el Hashing Trick para proyectarlas a un espacio de 1000 dimensiones. Algunas categorías colisionarán, pero las representaciones serán más eficientes para procesar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9d1b4",
   "metadata": {},
   "source": [
    "\n",
    "##### Ventajas:\n",
    "- **Escalabilidad**: Es muy eficiente cuando trabajas con **grandes volúmenes de datos categóricos** (con millones de categorías). No requiere almacenar un diccionario de todas las categorías.\n",
    "- **Dimensionalidad controlada**: Puedes elegir el número de dimensiones, lo que reduce la complejidad del modelo y el uso de memoria.\n",
    "- **Sin necesidad de datos de entrenamiento**: A diferencia de otras técnicas de codificación, no necesitas ver todos los datos antes de aplicar el hash, lo que lo hace adecuado para sistemas de producción con datos en flujo.\n",
    "\n",
    "##### Desventajas:\n",
    "- **Colisiones**: Dado que la misma posición en el vector puede ser asignada a varias categorías diferentes, puede haber pérdida de información debido a las colisiones de hash.\n",
    "- **Difícil interpretación**: Las categorías ya no tienen una representación directa o interpretable. Una vez codificadas, es difícil saber qué categoría corresponde a qué valor hash.\n",
    "  \n",
    "##### Ejemplo en Python usando `FeatureHasher`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45d1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "# Definir el hasher con el número de características deseadas\n",
    "hasher = FeatureHasher(n_features=10, input_type='string')\n",
    "\n",
    "# Lista de categorías a codificar\n",
    "categorias = [['Gato'], ['Perro'], ['Ratón'], ['Elefante'], ['Perro']]\n",
    "\n",
    "# Aplicar hashing\n",
    "hashed_features = hasher.transform(categorias)\n",
    "\n",
    "# Convertir a matriz densa para visualizar\n",
    "print(hashed_features.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148a7aec",
   "metadata": {},
   "source": [
    "\n",
    "En este ejemplo, los valores categóricos como \"Gato\", \"Perro\", etc., son codificados en un espacio de 10 dimensiones. Algunas categorías pueden compartir la misma columna debido a colisiones de hash.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc48d73",
   "metadata": {},
   "source": [
    "\n",
    "### Resumen de las Técnicas:\n",
    "\n",
    "| Técnica          | Descripción                                                                 | Aplicabilidad                                  | Ventajas                             | Desventajas                                  |\n",
    "|------------------|-----------------------------------------------------------------------------|------------------------------------------------|--------------------------------------|----------------------------------------------|\n",
    "| **Target Encoding** | Codifica cada categoría según la media del valor objetivo asociado.        | Variables categóricas no ordinales con muchas subcategorías. | Captura relaciones estadísticas, mejora rendimiento. | Riesgo de sobreajuste, bias en categorías raras. |\n",
    "| **Hashing**        | Usa una función hash para convertir categorías en valores numéricos.        | Variables categóricas con un gran número de subcategorías (escenario de big data). | Escalable, eficiente, sin necesidad de entrenamiento. | Posibles colisiones, difícil interpretación.      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7baaf",
   "metadata": {},
   "source": [
    "\n",
    "Ambas técnicas son útiles en situaciones donde el número de categorías es elevado, pero debes elegir la que mejor se adapte al tipo de datos y al modelo que estés utilizando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84f4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf16b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeba65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473deff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372033f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28160c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cce112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e67008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d71269f8",
   "metadata": {},
   "source": [
    "# Representación gráfica del camino que hemos seguido\n",
    "\n",
    "Existen varias bibliotecas de Python que permiten trazar y visualizar representaciones gráficas de *pipelines* asociados a modelos de *machine learning*. Estas herramientas son muy útiles para mostrar visualmente los pasos de preprocesamiento, las transformaciones y los modelos en talleres o clases. A continuación te menciono algunas de las bibliotecas más populares:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cd997",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **Scikit-learn's `plot_pipeline()`** (a partir de la versión 1.0)\n",
    "Scikit-learn, una de las bibliotecas más usadas en *machine learning*, introdujo la función `plot_pipeline()` en su versión 1.0. Esta función permite trazar visualizaciones de los *pipelines* creados con `Pipeline` o `FeatureUnion`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5ce1d",
   "metadata": {},
   "source": [
    "\n",
    "**Ejemplo**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a570e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import set_config\n",
    "from sklearn.utils import estimator_html_repr\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Cargar dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Crear pipeline\n",
    "pipe = make_pipeline(StandardScaler(), PCA(), LogisticRegression())\n",
    "\n",
    "# Configurar visualización\n",
    "set_config(display='diagram')  # Para obtener el diagrama de la pipeline\n",
    "\n",
    "# Mostrar la representación gráfica del pipeline en Jupyter Notebook\n",
    "pipe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1ec3b",
   "metadata": {},
   "source": [
    "\n",
    "Este código generará un diagrama visual que muestra las diferentes etapas del *pipeline* cuando se ejecuta en un cuaderno Jupyter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a980546c",
   "metadata": {},
   "source": [
    "\n",
    "**Ejemplo**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6697c5",
   "metadata": {},
   "source": [
    "\n",
    "Este código trazará un gráfico interactivo que se puede explorar para analizar cada componente del *pipeline*.\n",
    "\n",
    "### 3. **`Yellowbrick`**\n",
    "[`Yellowbrick`](https://www.scikit-yb.org/en/latest/) es una biblioteca de visualización que se integra con scikit-learn y facilita la creación de gráficos para visualizar el desempeño de los modelos en diferentes etapas del *pipeline*.\n",
    "\n",
    "**Cómo instalarla**:\n",
    "```bash\n",
    "pip install yellowbrick\n",
    "```\n",
    "\n",
    "**Ejemplo**:\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from yellowbrick.pipeline import PipelineVisualizer\n",
    "\n",
    "# Crear pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Visualizar pipeline\n",
    "viz = PipelineVisualizer(pipeline)\n",
    "viz.show()\n",
    "```\n",
    "\n",
    "Esto genera una visualización del flujo del *pipeline* en un diagrama sencillo.\n",
    "\n",
    "### 4. **`DAGsHub`**\n",
    "[DAGsHub](https://dagshub.com/) permite la visualización de *pipelines* en proyectos de *machine learning* y manejo de datos. Aunque es más una plataforma de colaboración, incluye visualizaciones que permiten ver el flujo de datos y etapas del *pipeline* de manera gráfica.\n",
    "\n",
    "### 5. **`TPOT`**\n",
    "[`TPOT`](https://epistasislab.github.io/tpot/) es una biblioteca de *auto machine learning* que genera automáticamente *pipelines* optimizados para diferentes problemas de *machine learning*. TPOT incluye visualizaciones de los *pipelines* generados.\n",
    "\n",
    "**Cómo instalarla**:\n",
    "```bash\n",
    "pip install tpot\n",
    "```\n",
    "\n",
    "**Ejemplo**:\n",
    "```python\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar dataset\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, train_size=0.75, test_size=0.25)\n",
    "\n",
    "# Crear y entrenar el modelo TPOT\n",
    "tpot = TPOTClassifier(verbosity=2, generations=5, population_size=20)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Exportar el pipeline a un archivo de Python\n",
    "tpot.export('tpot_pipeline.py')\n",
    "\n",
    "# Visualizar el pipeline generado\n",
    "tpot._optimized_pipeline\n",
    "```\n",
    "\n",
    "TPOT permite visualizar los *pipelines* que ha generado automáticamente para cada problema.\n",
    "\n",
    "### Conclusión:\n",
    "Si buscas una herramienta para visualizar *pipelines* en talleres, te recomendaría empezar con la función `plot_pipeline()` de scikit-learn, ya que es muy fácil de usar si ya trabajas con scikit-learn. Si necesitas algo más avanzado o interactivo, puedes explorar `PipelineProfiler` o `Yellowbrick`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd389568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d72747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726fc31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc539357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10bce0d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referentes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3c468",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "* [Chollet, F. (2021). Deep learning with Python. Simon and Schuster.](https://github.com/marco-canas/didactica_ciencia_datos/blob/main/2_referentes/chollet/Fran%C3%A7ois%20Chollet%20-%20Deep%20Learning%20with%20Python-Manning%20(2018).pdf)  \n",
    "  \n",
    "\n",
    "\n",
    "* [Recomendación de la UNESCO sobre ciencia abierta](https://unesdoc.unesco.org/ark:/48223/pf0000379949_spa)\n",
    "\n",
    "* [chatGPT](https://openai.com/blog/chatgpt)  \n",
    "\n",
    "* [Géron, A. (2017). Hands-on machine learning with scikit-learn and tensorflow: Concepts. Tools, and Techniques to build intelligent systems.](https://github.com/marco-canas/didactica_ciencia_datos/blob/main/2_referentes/geron/Hands-On%20Machine%20Learning-3nd_Edition(2022).pdf)  \n",
    "\n",
    "* [McKinney, W. (2012). Python for data analysis: Data wrangling with Pandas, NumPy, and IPython. \" O'Reilly Media, Inc.\".](https://github.com/marco-canas/didactica_ciencia_datos/blob/main/2_referentes/mckinney/Wes_McKinney.pdf)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65d6f9",
   "metadata": {},
   "source": [
    "# Como estudiante, encuentro que...   \n",
    "\n",
    "F: Mis Fortalezas son:     \n",
    "O: Mis Oportunidades son:    \n",
    "D: Mis Debilidades son:    \n",
    "A: Lo que Amenazas mi aprendizaje es:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e56a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [Evaluamos al profesor Marco Cañas Aquí](https://forms.office.com/Pages/ResponsePage.aspx?id=IefhmYRxjkmK_7KtTlPBwkanXIs1i1FEujpsZgO6dXpUREJPV1kxUk1JV1ozTFJIQVNIQjY5WEY3US4u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc9115",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agradecimientos  \n",
    "\n",
    "Doy gracias a Dios por la vida de mi Hijo Joseph Cañas Osorio y la madurez que ha alcanzado.\n",
    "\n",
    "Y a mi esposa Yasmira por su apoyo, orientación y acompañamiento. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
